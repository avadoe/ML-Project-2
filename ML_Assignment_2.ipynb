{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iUAirH6PMWwy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean,stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def standard_normal_distribution(x,avg,std):\n",
    "    return np.exp(-0.5*(x-avg)*(x-avg)/(std*std))/(np.sqrt(2*np.pi))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluation_summary(label,model_metrics):\n",
    "    print(f\"Model Name: {label}\\n\")\n",
    "    print(f\"Accuracy: {model_metrics['Accuracy']}\\n\")\n",
    "\n",
    "    if len(model_metrics):\n",
    "        print(f\"Precision: {model_metrics['Precision']}\\n\")\n",
    "        print(f\"Recall: {model_metrics['Recall']}\\n\")\n",
    "        print(f\"F1_Score: {model_metrics['F1_score']}\\n\")\n",
    "    print(f\"Confusion_Matrix:\\n {model_metrics['Confusion_Matrix']}\")"
   ],
   "metadata": {
    "id": "gVm34VzrE5ml",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def Eval_metrics(y_test,y_pred,num_classes):\n",
    "\n",
    "    confusion_matrix=np.zeros((num_classes,num_classes))\n",
    "    for i in range(y_test.shape[0]):\n",
    "        confusion_matrix[y_pred[i]][y_test[i]]=confusion_matrix[y_pred[i]][y_test[i]]+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    accuracy=0;\n",
    "    for i in range(num_classes):\n",
    "        accuracy=accuracy+confusion_matrix[i][i]\n",
    "    accuracy=accuracy/y_test.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    return {'Accuracy':accuracy,'Confusion_Matrix':confusion_matrix}"
   ],
   "metadata": {
    "id": "0WR0xQLzcQkZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def Eval_metrics_naive_bayes(y_test,y_pred):\n",
    "    tp=0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    fn=0\n",
    "    for i in range(y_test.shape[0]):\n",
    "        if y_test[i]==y_pred[i] and y_test[i]==1:\n",
    "            tp=tp+1\n",
    "        elif y_test[i]==y_pred[i] and y_test[i]==0:\n",
    "            tn=tn+1\n",
    "        elif y_test[i]!=y_pred[i] and y_pred[i]==1:\n",
    "            fp=fp+1\n",
    "        else:\n",
    "            fn=fn+1\n",
    "\n",
    "    accuracy=(tn+tp)/(tn+tp+fn+fp)\n",
    "    precision= tp / (tp + fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    f1_score=2*precision*recall/(precision+recall)\n",
    "    confusion_matrix=[(tp,fp),(fn,tn)]\n",
    "    df=pd.DataFrame(confusion_matrix)\n",
    "    df.index.name=None\n",
    "\n",
    "    return {'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1_score':f1_score,'Confusion_Matrix':df}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Part A** - *Naive Bayes Classifier to Predict Income*"
   ],
   "metadata": {
    "id": "i0V-LRWMaVBf",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Task 1- *Data Preprocessing*"
   ],
   "metadata": {
    "id": "M7BlCzhQaZGH",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",index_col=False,names=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\">=50K\"])\n",
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "xq6R3EsiUBtJ",
    "outputId": "64106a81-0e07-4e1f-81ae-b06556b42c53",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   age          workclass  fnlwgt   education  education-num  \\\n0   39          State-gov   77516   Bachelors             13   \n1   50   Self-emp-not-inc   83311   Bachelors             13   \n2   38            Private  215646     HS-grad              9   \n3   53            Private  234721        11th              7   \n4   28            Private  338409   Bachelors             13   \n\n        marital-status          occupation    relationship    race      sex  \\\n0        Never-married        Adm-clerical   Not-in-family   White     Male   \n1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n\n   capital-gain  capital-loss  hours-per-week  native-country   >=50K  \n0          2174             0              40   United-States   <=50K  \n1             0             0              13   United-States   <=50K  \n2             0             0              40   United-States   <=50K  \n3             0             0              40   United-States   <=50K  \n4             0             0              40            Cuba   <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>&gt;=50K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhpqAUe6UBVO",
    "outputId": "1847cb64-2716-4952-bbff-babe752ba4ca",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  >=50K           32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' White' ' Black' ' Asian-Pac-Islander' ' Amer-Indian-Eskimo' ' Other'] \n",
      " 5\n"
     ]
    }
   ],
   "source": [
    "print(df['race'].unique(), '\\n', df['race'].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "df['race']=df['race'].replace([' Black', \" White\", ' Asian-Pac-Islander', ' Other', ' Amer-Indian-Eskimo'],\n",
    "                              [1, 2, 3, 4, 5]\n",
    "                              )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(df['marital-status'].unique(), '\\n', df['marital-status'].nunique())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjW-b97VcV2N",
    "outputId": "00b8a9e4-1385-4dc4-e268-d682ca124461",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Never-married' ' Married-civ-spouse' ' Divorced'\n",
      " ' Married-spouse-absent' ' Separated' ' Married-AF-spouse' ' Widowed'] \n",
      " 7\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "df['marital-status']=df['marital-status'].replace([' Never-married', ' Married-civ-spouse', ' Divorced'\n",
    "                                                   ,' Married-spouse-absent', ' Separated', ' Married-AF-spouse', ' Widowed'],\n",
    "                              [1, 2, 3, 4, 5,6,7]\n",
    "                              )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'\n",
      " ' ?' ' Self-emp-inc' ' Without-pay' ' Never-worked'] \n",
      " 9\n"
     ]
    }
   ],
   "source": [
    "print(df['workclass'].unique(), '\\n', df['workclass'].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "df['workclass'].replace([' Private', ' Local-gov', ' ?', ' Self-emp-not-inc', ' Federal-gov', ' State-gov',\n",
    "                         ' Self-emp-inc', ' Without-pay', ' Never-worked'], [1, 2, 3, 4, 5, 6, 7, 8, 9], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Bachelors' ' HS-grad' ' 11th' ' Masters' ' 9th' ' Some-college'\n",
      " ' Assoc-acdm' ' Assoc-voc' ' 7th-8th' ' Doctorate' ' Prof-school'\n",
      " ' 5th-6th' ' 10th' ' 1st-4th' ' Preschool' ' 12th'] \n",
      " 15\n"
     ]
    }
   ],
   "source": [
    "print(df['education'].unique(), '\\n',df['occupation'].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df['education'].replace([' 11th', ' HS-grad', ' Assoc-acdm', ' Some-college', ' 10th', ' Prof-school',\n",
    "                         ' 7th-8th', ' Bachelors', ' Masters', ' Doctorate', ' 5th-6th', ' Assoc-voc', ' 9th',\n",
    "                         ' 12th', ' 1st-4th', ' Preschool'], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], inplace=True)"
   ],
   "metadata": {
    "id": "9Kgf6d4WcV0I",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(df['occupation'].unique(), \"\\n\" ,df['occupation'].nunique())"
   ],
   "metadata": {
    "id": "_LuMztUVcVvs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Adm-clerical' ' Exec-managerial' ' Handlers-cleaners' ' Prof-specialty'\n",
      " ' Other-service' ' Sales' ' Craft-repair' ' Transport-moving'\n",
      " ' Farming-fishing' ' Machine-op-inspct' ' Tech-support' ' ?'\n",
      " ' Protective-serv' ' Armed-Forces' ' Priv-house-serv'] \n",
      " 15\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df['occupation'].replace([' Machine-op-inspct', ' Farming-fishing', ' Protective-serv', ' ?',\n",
    "                          ' Other-service', ' Prof-specialty', ' Craft-repair', ' Adm-clerical',\n",
    "                          ' Exec-managerial', ' Tech-support', ' Sales', ' Priv-house-serv',\n",
    "                          ' Transport-moving', ' Handlers-cleaners', ' Armed-Forces'],\n",
    "                         [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], inplace=True\n",
    "                         )"
   ],
   "metadata": {
    "id": "Ig481BEicVsU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(df['relationship'].unique(), '\\n', df['relationship'].nunique())"
   ],
   "metadata": {
    "id": "7cCqg97AcVqR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Not-in-family' ' Husband' ' Wife' ' Own-child' ' Unmarried'\n",
      " ' Other-relative'] \n",
      " 6\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df['relationship'].replace([' Own-child', ' Husband', ' Not-in-family', ' Unmarried', ' Wife', ' Other-relative'],\n",
    "                           [1, 2, 3, 4, 5, 6], inplace=True)"
   ],
   "metadata": {
    "id": "lOOAAq_KcVno",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(df['sex'].unique(), '\\n', df['sex'].nunique())"
   ],
   "metadata": {
    "id": "pxxgx_xwcViu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Male' ' Female'] \n",
      " 2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df['sex'].replace([' Male', ' Female'], [0, 1], inplace=True)"
   ],
   "metadata": {
    "id": "JV-fgP92cVgV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "l = []\n",
    "for i in range(42):\n",
    "    l.append(i)"
   ],
   "metadata": {
    "id": "69l_NxkscVdv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['native-country'].replace([' United-States', ' ?', ' Peru', ' Guatemala', ' Mexico', ' Dominican-Republic',\n",
    "                              ' Ireland', ' Germany', ' Philippines', ' Thailand', ' Haiti', ' El-Salvador',\n",
    "                              ' Puerto-Rico', ' Vietnam', ' South', ' Columbia', ' Japan', ' India', ' Cambodia',\n",
    "                              ' Poland', ' Laos', ' England', ' Cuba', ' Taiwan', ' Italy', ' Canada', ' Portugal',\n",
    "                              ' China', ' Nicaragua', ' Honduras', ' Iran', ' Scotland', ' Jamaica', ' Ecuador',\n",
    "                              ' Yugoslavia', ' Hungary', ' Hong', ' Greece', ' Trinadad&Tobago',\n",
    "                              ' Outlying-US(Guam-USVI-etc)', ' France', ' Holand-Netherlands'], l, inplace=True)"
   ],
   "metadata": {
    "id": "aR-qresecVbN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 22 32 17  1  4 14 12 29 21 25  7 30  8 24 19 15 18  9 33 20 23 10 26\n",
      "  5 11 40  3 27 16 34  2 39 31 38 37 28 13 36  6 35 41] \n",
      " 42\n"
     ]
    }
   ],
   "source": [
    "print(df['native-country'].unique(), '\\n', df['native-country'].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df['>=50K'].replace([' <=50K', ' >50K'], [0, 1], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "df[\"age\"]=(df[\"age\"]-df[\"age\"].mean())/df[\"age\"].std()\n",
    "df[\"fnlwgt\"]=(df[\"fnlwgt\"]-df[\"fnlwgt\"].mean())/df[\"fnlwgt\"].std()\n",
    "df[\"education-num\"]=(df[\"education-num\"]-df[\"education-num\"].mean())/df[\"education-num\"].std()\n",
    "df[\"capital-gain\"]=(df[\"capital-gain\"]-df[\"capital-gain\"].mean())/df[\"capital-gain\"].std()\n",
    "df[\"capital-loss\"]=(df[\"capital-loss\"]-df[\"capital-loss\"].mean())/df[\"capital-loss\"].std()\n",
    "df[\"hours-per-week\"]=(df[\"hours-per-week\"]-df[\"hours-per-week\"].mean())/df[\"hours-per-week\"].std()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "            age  workclass    fnlwgt  education  education-num  \\\n0      0.030670          6 -1.063594          8       1.134721   \n1      0.837096          4 -1.008692          8       1.134721   \n2     -0.042641          1  0.245075          2      -0.420053   \n3      1.057031          1  0.425795          1      -1.197440   \n4     -0.775756          1  1.408154          8       1.134721   \n...         ...        ...       ...        ...            ...   \n32556 -0.849067          1  0.639731          3       0.746028   \n32557  0.103982          1 -0.335428          2      -0.420053   \n32558  1.423588          1 -0.358772          2      -0.420053   \n32559 -1.215625          1  0.110958          2      -0.420053   \n32560  0.983719          7  0.929878          2      -0.420053   \n\n       marital-status  occupation  relationship  race  sex  capital-gain  \\\n0                   1           8             3     2    0      0.148451   \n1                   2           9             2     2    0     -0.145918   \n2                   3          14             3     2    0     -0.145918   \n3                   2          14             2     1    0     -0.145918   \n4                   2           6             5     1    1     -0.145918   \n...               ...         ...           ...   ...  ...           ...   \n32556               2          10             5     2    1     -0.145918   \n32557               2           1             2     2    0     -0.145918   \n32558               7           8             4     2    1     -0.145918   \n32559               1           8             1     2    0     -0.145918   \n32560               2           9             5     2    1      1.888395   \n\n       capital-loss  hours-per-week  native-country  >=50K  \n0         -0.216656       -0.035429               0      0  \n1         -0.216656       -2.222119               0      0  \n2         -0.216656       -0.035429               0      0  \n3         -0.216656       -0.035429               0      0  \n4         -0.216656       -0.035429              22      0  \n...             ...             ...             ...    ...  \n32556     -0.216656       -0.197406               0      0  \n32557     -0.216656       -0.035429               0      1  \n32558     -0.216656       -0.035429               0      0  \n32559     -0.216656       -1.655199               0      0  \n32560     -0.216656       -0.035429               0      1  \n\n[32561 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>&gt;=50K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.030670</td>\n      <td>6</td>\n      <td>-1.063594</td>\n      <td>8</td>\n      <td>1.134721</td>\n      <td>1</td>\n      <td>8</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.148451</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.837096</td>\n      <td>4</td>\n      <td>-1.008692</td>\n      <td>8</td>\n      <td>1.134721</td>\n      <td>2</td>\n      <td>9</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-2.222119</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.042641</td>\n      <td>1</td>\n      <td>0.245075</td>\n      <td>2</td>\n      <td>-0.420053</td>\n      <td>3</td>\n      <td>14</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.057031</td>\n      <td>1</td>\n      <td>0.425795</td>\n      <td>1</td>\n      <td>-1.197440</td>\n      <td>2</td>\n      <td>14</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.775756</td>\n      <td>1</td>\n      <td>1.408154</td>\n      <td>8</td>\n      <td>1.134721</td>\n      <td>2</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32556</th>\n      <td>-0.849067</td>\n      <td>1</td>\n      <td>0.639731</td>\n      <td>3</td>\n      <td>0.746028</td>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-0.197406</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32557</th>\n      <td>0.103982</td>\n      <td>1</td>\n      <td>-0.335428</td>\n      <td>2</td>\n      <td>-0.420053</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32558</th>\n      <td>1.423588</td>\n      <td>1</td>\n      <td>-0.358772</td>\n      <td>2</td>\n      <td>-0.420053</td>\n      <td>7</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32559</th>\n      <td>-1.215625</td>\n      <td>1</td>\n      <td>0.110958</td>\n      <td>2</td>\n      <td>-0.420053</td>\n      <td>1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-1.655199</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32560</th>\n      <td>0.983719</td>\n      <td>7</td>\n      <td>0.929878</td>\n      <td>2</td>\n      <td>-0.420053</td>\n      <td>2</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.888395</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>32561 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Task 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "train_data=df.sample(frac=0.67,random_state=42)\n",
    "test_data=pd.concat([df,train_data]).drop_duplicates(keep=False)\n",
    "X_train=train_data.drop('>=50K',axis=1).values\n",
    "Y_train=train_data['>=50K'].values\n",
    "X_test=test_data.drop('>=50K',axis=1).values\n",
    "Y_test=test_data['>=50K'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.84906741,  1.        , -0.28043934, ..., -0.2166562 ,\n        -0.19740595,  0.        ],\n       [ 0.47053884,  6.        , -1.31891422, ..., -0.2166562 ,\n        -0.0354289 ,  0.        ],\n       [-0.70244449,  1.        , -0.03666857, ..., -0.2166562 ,\n         1.17939893,  0.        ],\n       ...,\n       [ 1.35027633,  1.        ,  1.62525504, ..., -0.2166562 ,\n        -0.0354289 ,  0.        ],\n       [-0.92237887,  1.        , -1.42836948, ..., -0.2166562 ,\n        -0.0354289 ,  5.        ],\n       [ 0.25060446,  1.        , -0.16703335, ..., -0.2166562 ,\n        -0.0354289 ,  0.        ]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "Continuous_features=[0,2,4,10,11,12]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "        age  workclass    fnlwgt  education  education-num  marital-status  \\\n0  0.030670          6 -1.063594          8       1.134721               1   \n1  0.837096          4 -1.008692          8       1.134721               2   \n2 -0.042641          1  0.245075          2      -0.420053               3   \n3  1.057031          1  0.425795          1      -1.197440               2   \n4 -0.775756          1  1.408154          8       1.134721               2   \n\n   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n0           8             3     2    0      0.148451     -0.216656   \n1           9             2     2    0     -0.145918     -0.216656   \n2          14             3     2    0     -0.145918     -0.216656   \n3          14             2     1    0     -0.145918     -0.216656   \n4           6             5     1    1     -0.145918     -0.216656   \n\n   hours-per-week  native-country  >=50K  \n0       -0.035429               0      0  \n1       -2.222119               0      0  \n2       -0.035429               0      0  \n3       -0.035429               0      0  \n4       -0.035429              22      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>&gt;=50K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.030670</td>\n      <td>6</td>\n      <td>-1.063594</td>\n      <td>8</td>\n      <td>1.134721</td>\n      <td>1</td>\n      <td>8</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.148451</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.837096</td>\n      <td>4</td>\n      <td>-1.008692</td>\n      <td>8</td>\n      <td>1.134721</td>\n      <td>2</td>\n      <td>9</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-2.222119</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.042641</td>\n      <td>1</td>\n      <td>0.245075</td>\n      <td>2</td>\n      <td>-0.420053</td>\n      <td>3</td>\n      <td>14</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.057031</td>\n      <td>1</td>\n      <td>0.425795</td>\n      <td>1</td>\n      <td>-1.197440</td>\n      <td>2</td>\n      <td>14</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.775756</td>\n      <td>1</td>\n      <td>1.408154</td>\n      <td>8</td>\n      <td>1.134721</td>\n      <td>2</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.145918</td>\n      <td>-0.216656</td>\n      <td>-0.035429</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "pos_neg_params=[]\n",
    "for i in Continuous_features:\n",
    "    pos=[]\n",
    "    neg=[]\n",
    "    for j in range(X_train.shape[0]):\n",
    "        if Y_train[j]==1:\n",
    "            pos.append(X_train[j][i])\n",
    "        else:\n",
    "            neg.append(X_train[j][i])\n",
    "    temp=[]\n",
    "    temp.append(mean(pos))\n",
    "    temp.append(stdev(pos))\n",
    "    temp.append(mean(neg))\n",
    "    temp.append(stdev(neg))\n",
    "    pos_neg_params.append(temp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def prior_probablity_each_class(Y_train,target):\n",
    "    count=0\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        if Y_train[i]==target:\n",
    "            count=count+1\n",
    "    return count/Y_train.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def conditional_probability_feature(feature_index,X_train,Y_train,target_class,feature):\n",
    "    if feature_index in Continuous_features:\n",
    "        pos=0\n",
    "        for i in range(len(Continuous_features)):\n",
    "            if Continuous_features[i]==feature_index:\n",
    "                pos=i\n",
    "                break\n",
    "        num=0\n",
    "        if target_class==1:\n",
    "            num=standard_normal_distribution(feature,pos_neg_params[pos][0],pos_neg_params[pos][1])\n",
    "        else:\n",
    "            num=standard_normal_distribution(feature,pos_neg_params[pos][2],pos_neg_params[pos][3])\n",
    "        return num\n",
    "    else:\n",
    "        den=0\n",
    "        count=0\n",
    "        for i in range(X_train.shape[0]):\n",
    "            if Y_train[i]==target_class:\n",
    "                den=den+1\n",
    "                if X_train[i][feature_index]==feature:\n",
    "                    count=count+1\n",
    "        return count/den\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def predict(X_train,Y_train,X_test,i):\n",
    "    p_pos=prior_probablity_each_class(Y_train,1)\n",
    "    p_neg=prior_probablity_each_class(Y_train,0)\n",
    "    for j in range(14):\n",
    "        p_pos=p_pos*conditional_probability_feature(j,X_train,Y_train,1,X_test[i][j])\n",
    "    for j in range(14):\n",
    "        p_neg=p_neg*conditional_probability_feature(j,X_train,Y_train,0,X_test[i][j])\n",
    "    if p_pos>=p_neg:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "Y_pred=[]\n",
    "for i in range(1500):\n",
    "    Y_pred.append(predict(X_train,Y_train,X_test,i))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Naive\n",
      "\n",
      "Accuracy: 0.8093333333333333\n",
      "\n",
      "Precision: 0.6042553191489362\n",
      "\n",
      "Recall: 0.7395833333333334\n",
      "\n",
      "F1_Score: 0.6651053864168619\n",
      "\n",
      "Confusion_Matrix:\n",
      "      0    1\n",
      "0  284  186\n",
      "1  100  930\n"
     ]
    }
   ],
   "source": [
    "metrics=Eval_metrics_naive_bayes(Y_test[:1500],Y_pred)\n",
    "evaluation_summary('Naive',metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Smoothing techinque"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def conditional_probability_feature_with_smoothing(feature_index,X_train,Y_train,target_class,feature):\n",
    "    if feature_index in Continuous_features:\n",
    "        pos=0\n",
    "        for i in range(len(Continuous_features)):\n",
    "            if Continuous_features[i]==feature_index:\n",
    "                pos=i\n",
    "                break\n",
    "\n",
    "        num=0\n",
    "        if target_class==1:\n",
    "            num=standard_normal_distribution(feature,pos_neg_params[pos][0],pos_neg_params[pos][1])\n",
    "        else:\n",
    "            num=standard_normal_distribution(feature,pos_neg_params[pos][2],pos_neg_params[pos][3])\n",
    "\n",
    "        return num\n",
    "    else:\n",
    "        den=0\n",
    "        count=0\n",
    "        nc=0\n",
    "        n=0\n",
    "        m=0\n",
    "        for i in range(X_train.shape[0]):\n",
    "            if Y_train[i]==target_class:\n",
    "                den=den+1\n",
    "                n=n+1\n",
    "                if X_train[i][feature_index]==feature:\n",
    "                    nc=nc+1\n",
    "                    count=count+1\n",
    "        if count!=0:\n",
    "            return count/den\n",
    "        # To handle 0 probabilities\n",
    "        m=len(np.unique(df.iloc[:,feature_index]))\n",
    "        return (nc+1)/(n+m)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "Y_pred=[]\n",
    "for i in range(1000):\n",
    "    Y_pred.append(predict(X_train,Y_train,X_test,i))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Naive\n",
      "\n",
      "Accuracy: 0.824\n",
      "\n",
      "Precision: 0.6185897435897436\n",
      "\n",
      "Recall: 0.772\n",
      "\n",
      "F1_Score: 0.6868327402135231\n",
      "\n",
      "Confusion_Matrix:\n",
      "      0    1\n",
      "0  193  119\n",
      "1   57  631\n"
     ]
    }
   ],
   "source": [
    "metrics=Eval_metrics_naive_bayes(Y_test[:1000],Y_pred)\n",
    "evaluation_summary('Naive',metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Logistic Regression\n",
      "\n",
      "Accuracy: 0.8250372856077554\n",
      "\n",
      "Precision: 0.4525631216526396\n",
      "\n",
      "Recall: 0.7262124002455494\n",
      "\n",
      "F1_Score: 0.5576243224133868\n",
      "\n",
      "Confusion_Matrix:\n",
      "       0     1\n",
      "0  1183  1431\n",
      "1   446  7668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred=classifier.predict(X_test)\n",
    "metrics=Eval_metrics_naive_bayes(Y_pred,Y_test)\n",
    "evaluation_summary('Logistic Regression',metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: K-Nearest Neighbours\n",
      "\n",
      "Accuracy: 0.8187919463087249\n",
      "\n",
      "Precision: 0.5734506503442999\n",
      "\n",
      "Recall: 0.6439003436426117\n",
      "\n",
      "F1_Score: 0.6066369890732497\n",
      "\n",
      "Confusion_Matrix:\n",
      "       0     1\n",
      "0  1499  1115\n",
      "1   829  7285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred=classifier.predict(X_test)\n",
    "metrics=Eval_metrics_naive_bayes(Y_pred,Y_test)\n",
    "evaluation_summary('K-Nearest Neighbours',metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part B"
   ],
   "metadata": {
    "id": "BvAwe-SsRGKl",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing Dataset"
   ],
   "metadata": {
    "id": "kFJNv4E3RW45",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.activations import sigmoid,relu,linear,softmax,tanh\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy,SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD,Adam"
   ],
   "metadata": {
    "id": "CscZOYH-R1GR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_test=tf.constant(X_test)"
   ],
   "metadata": {
    "id": "vbOL-Z9LPt22",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_test.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xd_znhGsf9Gy",
    "outputId": "ba8664c4-0310-4b28-9579-6ec2b1e003c1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([10000, 28, 28])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train.shape,Y_train.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JENCbLcqTmt0",
    "outputId": "5ae3d4e7-81df-42c1-987a-f1bc6ed727c8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "((60000, 28, 28), (60000,))"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train=tf.constant(X_train)\n",
    "Y_train=tf.constant(Y_train)"
   ],
   "metadata": {
    "id": "g8O8NPoYXl1M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model 1"
   ],
   "metadata": {
    "id": "GD9rKNhOdG_f",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "g0AkJiHDT7eL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_1=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_1.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_1.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "  num=model_1.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "  Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_1',metrics)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "EkjnQiNfSQEm",
    "outputId": "c974ffbb-375e-4994-c7a9-70bcfb5af974",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [32]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     11\u001B[0m Y_pred\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(X_test\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m---> 13\u001B[0m   num\u001B[38;5;241m=\u001B[39m\u001B[43mmodel_1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39margmax()\n\u001B[1;32m     14\u001B[0m   Y_pred\u001B[38;5;241m.\u001B[39mappend(num)\n\u001B[1;32m     16\u001B[0m metrics\u001B[38;5;241m=\u001B[39mEval_metrics(Y_test,Y_pred)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2220\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   2211\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m   2212\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   2213\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2214\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2217\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m   2218\u001B[0m         )\n\u001B[0;32m-> 2220\u001B[0m data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2223\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2224\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2226\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2227\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2228\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2229\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2230\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2231\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2233\u001B[0m \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[1;32m   2234\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:1582\u001B[0m, in \u001B[0;36mget_data_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cluster_coordinator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1582\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataHandler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:1262\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[1;32m   1259\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution \u001B[38;5;241m=\u001B[39m steps_per_execution\n\u001B[1;32m   1261\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m select_data_adapter(x, y)\n\u001B[0;32m-> 1262\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m \u001B[43madapter_cls\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1268\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1272\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1274\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1277\u001B[0m strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[1;32m   1279\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:349\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.__init__\u001B[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[1;32m    345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m flat_dataset\n\u001B[1;32m    347\u001B[0m indices_dataset \u001B[38;5;241m=\u001B[39m indices_dataset\u001B[38;5;241m.\u001B[39mflat_map(slice_batch_indices)\n\u001B[0;32m--> 349\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mslice_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindices_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    353\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshuffle_batch\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch):\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:390\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.slice_inputs\u001B[0;34m(self, indices_dataset, inputs)\u001B[0m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgrab_batch\u001B[39m(i, data):\n\u001B[1;32m    386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[1;32m    387\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m d: tf\u001B[38;5;241m.\u001B[39mgather(d, i, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), data\n\u001B[1;32m    388\u001B[0m     )\n\u001B[0;32m--> 390\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrab_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAUTOTUNE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;66;03m# Default optimizations are disabled to avoid the overhead of\u001B[39;00m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;66;03m# (unnecessary) input pipeline graph serialization and deserialization\u001B[39;00m\n\u001B[1;32m    394\u001B[0m options \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mOptions()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2204\u001B[0m, in \u001B[0;36mDatasetV2.map\u001B[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[1;32m   2202\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m MapDataset(\u001B[38;5;28mself\u001B[39m, map_func, preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[1;32m   2203\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2204\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mParallelMapDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2205\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2206\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2207\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2208\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2209\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2210\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:5441\u001B[0m, in \u001B[0;36mParallelMapDataset.__init__\u001B[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001B[0m\n\u001B[1;32m   5439\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_dataset \u001B[38;5;241m=\u001B[39m input_dataset\n\u001B[1;32m   5440\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_inter_op_parallelism \u001B[38;5;241m=\u001B[39m use_inter_op_parallelism\n\u001B[0;32m-> 5441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mstructured_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5442\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5443\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5444\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5445\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_legacy_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_legacy_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5446\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m deterministic \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5447\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deterministic \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[1;32m    264\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    265\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    266\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    267\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    268\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    269\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[0;32m--> 271\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[1;32m    273\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2610\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2601\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   2602\u001B[0m   \u001B[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001B[39;00m\n\u001B[1;32m   2603\u001B[0m \n\u001B[1;32m   2604\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2608\u001B[0m \u001B[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001B[39;00m\n\u001B[1;32m   2609\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2610\u001B[0m   graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_concrete_function_garbage_collected\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2611\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2612\u001B[0m   graph_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   2613\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2576\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2574\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2575\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m-> 2576\u001B[0m   graph_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2577\u001B[0m   seen_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m   2578\u001B[0m   captured \u001B[38;5;241m=\u001B[39m object_identity\u001B[38;5;241m.\u001B[39mObjectIdentitySet(\n\u001B[1;32m   2579\u001B[0m       graph_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minternal_captures)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2760\u001B[0m, in \u001B[0;36mFunction._maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   2758\u001B[0m   \u001B[38;5;66;03m# Only get placeholders for arguments, not captures\u001B[39;00m\n\u001B[1;32m   2759\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m placeholder_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m-> 2760\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2762\u001B[0m graph_capture_container \u001B[38;5;241m=\u001B[39m graph_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39m_capture_func_lib  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   2763\u001B[0m \u001B[38;5;66;03m# Maintain the list of all captures\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2670\u001B[0m, in \u001B[0;36mFunction._create_graph_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   2665\u001B[0m missing_arg_names \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   2666\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (arg, i) \u001B[38;5;28;01mfor\u001B[39;00m i, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(missing_arg_names)\n\u001B[1;32m   2667\u001B[0m ]\n\u001B[1;32m   2668\u001B[0m arg_names \u001B[38;5;241m=\u001B[39m base_arg_names \u001B[38;5;241m+\u001B[39m missing_arg_names\n\u001B[1;32m   2669\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m ConcreteFunction(\n\u001B[0;32m-> 2670\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2671\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2672\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2673\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2675\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2678\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2679\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   2680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[1;32m   2681\u001B[0m     spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[1;32m   2682\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[1;32m   2683\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[1;32m   2684\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[1;32m   2685\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[1;32m   2686\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   2687\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1288\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001B[0m\n\u001B[1;32m   1282\u001B[0m   \u001B[38;5;66;03m# Returning a closed-over tensor does not trigger convert_to_tensor.\u001B[39;00m\n\u001B[1;32m   1283\u001B[0m   func_graph\u001B[38;5;241m.\u001B[39moutputs\u001B[38;5;241m.\u001B[39mextend(\n\u001B[1;32m   1284\u001B[0m       func_graph\u001B[38;5;241m.\u001B[39mcapture(x)\n\u001B[1;32m   1285\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m flatten(func_graph\u001B[38;5;241m.\u001B[39mstructured_outputs)\n\u001B[1;32m   1286\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 1288\u001B[0m   func_graph\u001B[38;5;241m.\u001B[39mvariables \u001B[38;5;241m=\u001B[39m variables\n\u001B[1;32m   1290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m add_control_dependencies:\n\u001B[1;32m   1291\u001B[0m   func_graph\u001B[38;5;241m.\u001B[39mcontrol_outputs\u001B[38;5;241m.\u001B[39mextend(deps_control_manager\u001B[38;5;241m.\u001B[39mops_which_must_run)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/auto_control_deps.py:415\u001B[0m, in \u001B[0;36mAutomaticControlDependencies.__exit__\u001B[0;34m(self, unused_type, unused_value, unused_traceback)\u001B[0m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;66;03m# Ensures that uses of resource tensors get serialized properly and all\u001B[39;00m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;66;03m# execute. This is done by keeping a map from resource tensor to the last op\u001B[39;00m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;66;03m# in graph-construction order which used it (last_write_to_resource).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;66;03m# test that it works. Support while loops. Support init_scope escaping from\u001B[39;00m\n\u001B[1;32m    412\u001B[0m \u001B[38;5;66;03m# this.\u001B[39;00m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m op \u001B[38;5;129;01min\u001B[39;00m new_operations:\n\u001B[1;32m    414\u001B[0m   \u001B[38;5;66;03m# TODO(apassos) make this code safely support while loops.\u001B[39;00m\n\u001B[0;32m--> 415\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mcontrol_flow_util\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIsInWhileLoop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    416\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    417\u001B[0m   control_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_util.py:80\u001B[0m, in \u001B[0;36mIsInWhileLoop\u001B[0;34m(op)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mIsInWhileLoop\u001B[39m(op):\n\u001B[1;32m     79\u001B[0m   ctxt \u001B[38;5;241m=\u001B[39m op\u001B[38;5;241m.\u001B[39m_get_control_flow_context()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m---> 80\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mGetContainingWhileContext\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctxt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_2.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_2.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_2.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_2',metrics)\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "eAYKyt-WT7eM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Model_3\n",
      "\n",
      "Accuracy: 0.888\n",
      "\n",
      "Confusion_Matrix:\n",
      " [[ 83.   0.   3.   0.   0.   4.   3.   0.   1.   0.]\n",
      " [  0. 125.   0.   1.   0.   0.   0.   1.   0.   1.]\n",
      " [  0.   0. 105.   3.   0.   1.   0.   3.   4.   0.]\n",
      " [  0.   0.   3.  91.   0.   5.   0.   3.   8.   1.]\n",
      " [  0.   0.   0.   0.  88.   0.   0.   1.   1.   3.]\n",
      " [  0.   0.   0.   3.   0.  74.   1.   0.   1.   0.]\n",
      " [  2.   0.   1.   1.   3.   1.  83.   0.   3.   0.]\n",
      " [  0.   0.   1.   2.   0.   0.   0.  85.   1.   1.]\n",
      " [  0.   1.   3.   5.   1.   1.   0.   1.  69.   3.]\n",
      " [  0.   0.   0.   1.  18.   1.   0.   5.   1.  85.]]\n"
     ]
    }
   ],
   "source": [
    "model_3=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=tanh),\n",
    "    Dense(100,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_3.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_3.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_3.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_3',metrics)\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "9QmHMft4T7eM",
    "outputId": "06005096-b936-488c-a900-cc9aabf658fe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_4=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_4.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_4.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_4.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_4',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7gIBEZYpT7eM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Model_5\n",
      "\n",
      "Accuracy: 0.799\n",
      "\n",
      "Confusion_Matrix:\n",
      " [[ 82.   0.   1.   0.   0.   0.  10.   0.   0.   0.]\n",
      " [  0. 124.  28.   0.   0.   3.   0.   0.   0.   0.]\n",
      " [  0.   0.  81.  49.   2.   7.   0.   1.   1.   1.]\n",
      " [  2.   0.   2.  56.   0.  37.   0.   4.   3.   7.]\n",
      " [  0.   0.   0.   0. 101.   1.   1.   0.   2.   2.]\n",
      " [  0.   0.   1.   1.   0.  36.   3.   1.   1.   4.]\n",
      " [  1.   0.   0.   0.   2.   0.  72.   0.   0.   0.]\n",
      " [  0.   0.   1.   1.   0.   0.   0.  90.   1.   0.]\n",
      " [  0.   2.   1.   0.   1.   2.   1.   2.  80.   3.]\n",
      " [  0.   0.   1.   0.   4.   1.   0.   1.   1.  77.]]\n"
     ]
    }
   ],
   "source": [
    "model_5=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(10,activation=sigmoid)\n",
    "])\n",
    "\n",
    "model_5.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_5.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_5.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_5',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lX2QqWs8T7eM",
    "outputId": "3b02e567-baf5-4a8b-eaf8-4525aaa1295f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Model_6\n",
      "\n",
      "Accuracy: 0.917\n",
      "\n",
      "Confusion_Matrix:\n",
      " [[ 83.   0.   0.   1.   1.   1.   4.   1.   3.   0.]\n",
      " [  0. 124.   0.   0.   1.   0.   0.   0.   0.   0.]\n",
      " [  0.   0. 104.   1.   1.   0.   0.   0.   1.   0.]\n",
      " [  1.   0.   1. 101.   0.   2.   0.   3.   1.   0.]\n",
      " [  0.   0.   0.   0.  97.   1.   0.   1.   2.   5.]\n",
      " [  0.   1.   1.   2.   0.  75.   1.   0.   1.   0.]\n",
      " [  1.   0.   0.   0.   1.   3.  82.   0.   1.   0.]\n",
      " [  0.   0.   4.   0.   1.   1.   0.  92.   0.   1.]\n",
      " [  0.   1.   5.   1.   1.   3.   0.   0.  75.   4.]\n",
      " [  0.   0.   1.   1.   7.   1.   0.   2.   5.  84.]]\n"
     ]
    }
   ],
   "source": [
    "model_6=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_6.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_6.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_6.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_6',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7fyVt7vTT7eN",
    "outputId": "ea4de560-db4e-4180-b673-3cc8a095c550"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_7=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_7.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_7.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_7.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_7',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "eGYpoI-2T7eN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_8=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_8.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_8.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_8.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_8',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "CSEuoGMvT7eN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_9=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=sigmoid),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_9.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_9.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_9.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_9',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Dli-AsuHT7eN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_10=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=sigmoid),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_10.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_10.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_10.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_10',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dl1LjIc7T7eN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_11=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=sigmoid),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_11.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_11.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_11.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_11',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "quPJaqhwT7eN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [33]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     11\u001B[0m Y_pred\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(X_test\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m---> 13\u001B[0m     num\u001B[38;5;241m=\u001B[39m\u001B[43mmodel_12\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39margmax()\n\u001B[1;32m     14\u001B[0m     Y_pred\u001B[38;5;241m.\u001B[39mappend(num)\n\u001B[1;32m     16\u001B[0m metrics\u001B[38;5;241m=\u001B[39mEval_metrics(Y_test,Y_pred)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2249\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   2247\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_predict_begin()\n\u001B[1;32m   2248\u001B[0m batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2249\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, iterator \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39menumerate_epochs():  \u001B[38;5;66;03m# Single epoch.\u001B[39;00m\n\u001B[1;32m   2250\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[1;32m   2251\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:1307\u001B[0m, in \u001B[0;36mDataHandler.enumerate_epochs\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1305\u001B[0m \u001B[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001B[39;00m\n\u001B[1;32m   1306\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_truncate_execution_to_epoch():\n\u001B[0;32m-> 1307\u001B[0m     data_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1308\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial_epoch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_epochs):\n\u001B[1;32m   1309\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:499\u001B[0m, in \u001B[0;36mDatasetV2.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minside_function():\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[0;32m--> 499\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43miterator_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOwnedIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    501\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset` only supports Python-style \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    502\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miteration in eager mode or within tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:696\u001B[0m, in \u001B[0;36mOwnedIterator.__init__\u001B[0;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[1;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m element_spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    693\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    694\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    695\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot be specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 696\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_next_call_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:721\u001B[0m, in \u001B[0;36mOwnedIterator._create_iterator\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(ds_variant):\n\u001B[1;32m    717\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    718\u001B[0m       gen_dataset_ops\u001B[38;5;241m.\u001B[39manonymous_iterator_v3(\n\u001B[1;32m    719\u001B[0m           output_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_types,\n\u001B[1;32m    720\u001B[0m           output_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_shapes))\n\u001B[0;32m--> 721\u001B[0m   \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_variant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3409\u001B[0m, in \u001B[0;36mmake_iterator\u001B[0;34m(dataset, iterator, name)\u001B[0m\n\u001B[1;32m   3407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m   3408\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3409\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3410\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMakeIterator\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3411\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   3412\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_12=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=sigmoid),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_12.compile(optimizer='sgd',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_12.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_12.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_12',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "4JjRuTjRT7eO",
    "outputId": "47006a32-8a99-4b5f-fbd7-a2f931ae8d27"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_13=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_13.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_13.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_13.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_13',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lwcHU6ZST7eO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_14=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_14.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_14.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_14.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_14',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Ij3EePo8T7eO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_14=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_14.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_14.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_14.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_14',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "eq29kPcsT7eO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_15=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_15.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_15.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_15.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_15',metrics)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Q0j0ZWCPT7eO"
   }
  }
 ]
}