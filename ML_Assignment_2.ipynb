{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iUAirH6PMWwy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean,stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def standard_normal_distribution(x,avg,std):\n",
    "    return np.exp(-0.5*(x-avg)*(x-avg)/(std*std))/(np.sqrt(2*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "gVm34VzrE5ml"
   },
   "outputs": [],
   "source": [
    "def evaluation_summary(label,model_metrics):\n",
    "    print(f\"Model Name: {label}\\n\")\n",
    "    print(f\"Accuracy: {model_metrics['Accuracy']}\\n\")\n",
    "\n",
    "    if len(model_metrics):\n",
    "        print(f\"Precision: {model_metrics['Precision']}\\n\")\n",
    "        print(f\"Recall: {model_metrics['Recall']}\\n\")\n",
    "        print(f\"F1_Score: {model_metrics['F1_score']}\\n\")\n",
    "    print(f\"Confusion_Matrix:\\n {model_metrics['Confusion_Matrix']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "0WR0xQLzcQkZ"
   },
   "outputs": [],
   "source": [
    "def Eval_metrics(y_test,y_pred,num_classes):\n",
    "\n",
    "    confusion_matrix=np.zeros((num_classes,num_classes))\n",
    "    for i in range(y_test.shape[0]):\n",
    "        confusion_matrix[y_pred[i]][y_test[i]]=confusion_matrix[y_pred[i]][y_test[i]]+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    accuracy=0;\n",
    "    for i in range(num_classes):\n",
    "        accuracy=accuracy+confusion_matrix[i][i]\n",
    "    accuracy=accuracy/y_test.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    return {'Accuracy':accuracy,'Confusion_Matrix':confusion_matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Eval_metrics_naive_bayes(y_test,y_pred):\n",
    "    tp=0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    fn=0\n",
    "    for i in range(y_test.shape[0]):\n",
    "        if y_test[i]==y_pred[i] and y_test[i]==1:\n",
    "            tp=tp+1\n",
    "        elif y_test[i]==y_pred[i] and y_test[i]==0:\n",
    "            tn=tn+1\n",
    "        elif y_test[i]!=y_pred[i] and y_pred[i]==1:\n",
    "            fp=fp+1\n",
    "        else:\n",
    "            fn=fn+1\n",
    "\n",
    "    accuracy=(tn+tp)/(tn+tp+fn+fp)\n",
    "    precision= tp / (tp + fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    f1_score=2*precision*recall/(precision+recall)\n",
    "    confusion_matrix=[(tp,fp),(fn,tn)]\n",
    "    df=pd.DataFrame(confusion_matrix)\n",
    "    df.index.name=None\n",
    "\n",
    "    return {'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1_score':f1_score,'Confusion_Matrix':df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0V-LRWMaVBf"
   },
   "source": [
    "**Part A** - *Naive Bayes Classifier to Predict Income*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7BlCzhQaZGH"
   },
   "source": [
    "Task 1- *Data Preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "xq6R3EsiUBtJ",
    "outputId": "64106a81-0e07-4e1f-81ae-b06556b42c53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>&gt;=50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country   >=50K  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",index_col=False,names=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\">=50K\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhpqAUe6UBVO",
    "outputId": "1847cb64-2716-4952-bbff-babe752ba4ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  >=50K           32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' White' ' Black' ' Asian-Pac-Islander' ' Amer-Indian-Eskimo' ' Other'] \n",
      " 5\n"
     ]
    }
   ],
   "source": [
    "print(df['race'].unique(), '\\n', df['race'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['race']=df['race'].replace([' Black', \" White\", ' Asian-Pac-Islander', ' Other', ' Amer-Indian-Eskimo'],\n",
    "                              [1, 2, 3, 4, 5]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjW-b97VcV2N",
    "outputId": "00b8a9e4-1385-4dc4-e268-d682ca124461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Never-married' ' Married-civ-spouse' ' Divorced'\n",
      " ' Married-spouse-absent' ' Separated' ' Married-AF-spouse' ' Widowed'] \n",
      " 7\n"
     ]
    }
   ],
   "source": [
    "print(df['marital-status'].unique(), '\\n', df['marital-status'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['marital-status']=df['marital-status'].replace([' Never-married', ' Married-civ-spouse', ' Divorced'\n",
    "                                                   ,' Married-spouse-absent', ' Separated', ' Married-AF-spouse', ' Widowed'],\n",
    "                              [1, 2, 3, 4, 5,6,7]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'\n",
      " ' ?' ' Self-emp-inc' ' Without-pay' ' Never-worked'] \n",
      " 9\n"
     ]
    }
   ],
   "source": [
    "print(df['workclass'].unique(), '\\n', df['workclass'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['workclass'].replace([' Private', ' Local-gov', ' ?', ' Self-emp-not-inc', ' Federal-gov', ' State-gov',\n",
    "                         ' Self-emp-inc', ' Without-pay', ' Never-worked'], [1, 2, 3, 4, 5, 6, 7, 8, 9], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Bachelors' ' HS-grad' ' 11th' ' Masters' ' 9th' ' Some-college'\n",
      " ' Assoc-acdm' ' Assoc-voc' ' 7th-8th' ' Doctorate' ' Prof-school'\n",
      " ' 5th-6th' ' 10th' ' 1st-4th' ' Preschool' ' 12th'] \n",
      " 15\n"
     ]
    }
   ],
   "source": [
    "print(df['education'].unique(), '\\n',df['occupation'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9Kgf6d4WcV0I"
   },
   "outputs": [],
   "source": [
    "df['education'].replace([' 11th', ' HS-grad', ' Assoc-acdm', ' Some-college', ' 10th', ' Prof-school',\n",
    "                         ' 7th-8th', ' Bachelors', ' Masters', ' Doctorate', ' 5th-6th', ' Assoc-voc', ' 9th',\n",
    "                         ' 12th', ' 1st-4th', ' Preschool'], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_LuMztUVcVvs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Adm-clerical' ' Exec-managerial' ' Handlers-cleaners' ' Prof-specialty'\n",
      " ' Other-service' ' Sales' ' Craft-repair' ' Transport-moving'\n",
      " ' Farming-fishing' ' Machine-op-inspct' ' Tech-support' ' ?'\n",
      " ' Protective-serv' ' Armed-Forces' ' Priv-house-serv'] \n",
      " 15\n"
     ]
    }
   ],
   "source": [
    "print(df['occupation'].unique(), \"\\n\" ,df['occupation'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Ig481BEicVsU"
   },
   "outputs": [],
   "source": [
    "df['occupation'].replace([' Machine-op-inspct', ' Farming-fishing', ' Protective-serv', ' ?',\n",
    "                          ' Other-service', ' Prof-specialty', ' Craft-repair', ' Adm-clerical',\n",
    "                          ' Exec-managerial', ' Tech-support', ' Sales', ' Priv-house-serv',\n",
    "                          ' Transport-moving', ' Handlers-cleaners', ' Armed-Forces'],\n",
    "                         [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], inplace=True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7cCqg97AcVqR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Not-in-family' ' Husband' ' Wife' ' Own-child' ' Unmarried'\n",
      " ' Other-relative'] \n",
      " 6\n"
     ]
    }
   ],
   "source": [
    "print(df['relationship'].unique(), '\\n', df['relationship'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "lOOAAq_KcVno"
   },
   "outputs": [],
   "source": [
    "df['relationship'].replace([' Own-child', ' Husband', ' Not-in-family', ' Unmarried', ' Wife', ' Other-relative'],\n",
    "                           [1, 2, 3, 4, 5, 6], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "pxxgx_xwcViu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Male' ' Female'] \n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "print(df['sex'].unique(), '\\n', df['sex'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "JV-fgP92cVgV"
   },
   "outputs": [],
   "source": [
    "df['sex'].replace([' Male', ' Female'], [0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "69l_NxkscVdv"
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(42):\n",
    "    l.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "aR-qresecVbN"
   },
   "outputs": [],
   "source": [
    "df['native-country'].replace([' United-States', ' ?', ' Peru', ' Guatemala', ' Mexico', ' Dominican-Republic',\n",
    "                              ' Ireland', ' Germany', ' Philippines', ' Thailand', ' Haiti', ' El-Salvador',\n",
    "                              ' Puerto-Rico', ' Vietnam', ' South', ' Columbia', ' Japan', ' India', ' Cambodia',\n",
    "                              ' Poland', ' Laos', ' England', ' Cuba', ' Taiwan', ' Italy', ' Canada', ' Portugal',\n",
    "                              ' China', ' Nicaragua', ' Honduras', ' Iran', ' Scotland', ' Jamaica', ' Ecuador',\n",
    "                              ' Yugoslavia', ' Hungary', ' Hong', ' Greece', ' Trinadad&Tobago',\n",
    "                              ' Outlying-US(Guam-USVI-etc)', ' France', ' Holand-Netherlands'], l, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 22 32 17  1  4 14 12 29 21 25  7 30  8 24 19 15 18  9 33 20 23 10 26\n",
      "  5 11 40  3 27 16 34  2 39 31 38 37 28 13 36  6 35 41] \n",
      " 42\n"
     ]
    }
   ],
   "source": [
    "print(df['native-country'].unique(), '\\n', df['native-country'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['>=50K'].replace([' <=50K', ' >50K'], [0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"age\"]=(df[\"age\"]-df[\"age\"].mean())/df[\"age\"].std()\n",
    "df[\"fnlwgt\"]=(df[\"fnlwgt\"]-df[\"fnlwgt\"].mean())/df[\"fnlwgt\"].std()\n",
    "df[\"education-num\"]=(df[\"education-num\"]-df[\"education-num\"].mean())/df[\"education-num\"].std()\n",
    "df[\"capital-gain\"]=(df[\"capital-gain\"]-df[\"capital-gain\"].mean())/df[\"capital-gain\"].std()\n",
    "df[\"capital-loss\"]=(df[\"capital-loss\"]-df[\"capital-loss\"].mean())/df[\"capital-loss\"].std()\n",
    "df[\"hours-per-week\"]=(df[\"hours-per-week\"]-df[\"hours-per-week\"].mean())/df[\"hours-per-week\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>&gt;=50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030670</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.063594</td>\n",
       "      <td>8</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837096</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.008692</td>\n",
       "      <td>8</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-2.222119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042641</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245075</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.057031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425795</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.197440</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775756</td>\n",
       "      <td>1</td>\n",
       "      <td>1.408154</td>\n",
       "      <td>8</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>-0.849067</td>\n",
       "      <td>1</td>\n",
       "      <td>0.639731</td>\n",
       "      <td>3</td>\n",
       "      <td>0.746028</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.197406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0.103982</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.335428</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>1.423588</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.358772</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>-1.215625</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110958</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-1.655199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0.983719</td>\n",
       "      <td>7</td>\n",
       "      <td>0.929878</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888395</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass    fnlwgt  education  education-num  \\\n",
       "0      0.030670          6 -1.063594          8       1.134721   \n",
       "1      0.837096          4 -1.008692          8       1.134721   \n",
       "2     -0.042641          1  0.245075          2      -0.420053   \n",
       "3      1.057031          1  0.425795          1      -1.197440   \n",
       "4     -0.775756          1  1.408154          8       1.134721   \n",
       "...         ...        ...       ...        ...            ...   \n",
       "32556 -0.849067          1  0.639731          3       0.746028   \n",
       "32557  0.103982          1 -0.335428          2      -0.420053   \n",
       "32558  1.423588          1 -0.358772          2      -0.420053   \n",
       "32559 -1.215625          1  0.110958          2      -0.420053   \n",
       "32560  0.983719          7  0.929878          2      -0.420053   \n",
       "\n",
       "       marital-status  occupation  relationship  race  sex  capital-gain  \\\n",
       "0                   1           8             3     2    0      0.148451   \n",
       "1                   2           9             2     2    0     -0.145918   \n",
       "2                   3          14             3     2    0     -0.145918   \n",
       "3                   2          14             2     1    0     -0.145918   \n",
       "4                   2           6             5     1    1     -0.145918   \n",
       "...               ...         ...           ...   ...  ...           ...   \n",
       "32556               2          10             5     2    1     -0.145918   \n",
       "32557               2           1             2     2    0     -0.145918   \n",
       "32558               7           8             4     2    1     -0.145918   \n",
       "32559               1           8             1     2    0     -0.145918   \n",
       "32560               2           9             5     2    1      1.888395   \n",
       "\n",
       "       capital-loss  hours-per-week  native-country  >=50K  \n",
       "0         -0.216656       -0.035429               0      0  \n",
       "1         -0.216656       -2.222119               0      0  \n",
       "2         -0.216656       -0.035429               0      0  \n",
       "3         -0.216656       -0.035429               0      0  \n",
       "4         -0.216656       -0.035429              22      0  \n",
       "...             ...             ...             ...    ...  \n",
       "32556     -0.216656       -0.197406               0      0  \n",
       "32557     -0.216656       -0.035429               0      1  \n",
       "32558     -0.216656       -0.035429               0      0  \n",
       "32559     -0.216656       -1.655199               0      0  \n",
       "32560     -0.216656       -0.035429               0      1  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data=df.sample(frac=0.67,random_state=42)\n",
    "test_data=pd.concat([df,train_data]).drop_duplicates(keep=False)\n",
    "X_train=train_data.drop('>=50K',axis=1).values\n",
    "Y_train=train_data['>=50K'].values\n",
    "X_test=test_data.drop('>=50K',axis=1).values\n",
    "Y_test=test_data['>=50K'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.84906741,  1.        , -0.28043934, ..., -0.2166562 ,\n",
       "        -0.19740595,  0.        ],\n",
       "       [ 0.47053884,  6.        , -1.31891422, ..., -0.2166562 ,\n",
       "        -0.0354289 ,  0.        ],\n",
       "       [-0.70244449,  1.        , -0.03666857, ..., -0.2166562 ,\n",
       "         1.17939893,  0.        ],\n",
       "       ...,\n",
       "       [ 1.35027633,  1.        ,  1.62525504, ..., -0.2166562 ,\n",
       "        -0.0354289 ,  0.        ],\n",
       "       [-0.92237887,  1.        , -1.42836948, ..., -0.2166562 ,\n",
       "        -0.0354289 ,  5.        ],\n",
       "       [ 0.25060446,  1.        , -0.16703335, ..., -0.2166562 ,\n",
       "        -0.0354289 ,  0.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Continuous_features=[0,2,4,10,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>&gt;=50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030670</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.063594</td>\n",
       "      <td>8</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837096</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.008692</td>\n",
       "      <td>8</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-2.222119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042641</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245075</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.057031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425795</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.197440</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775756</td>\n",
       "      <td>1</td>\n",
       "      <td>1.408154</td>\n",
       "      <td>8</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education-num  marital-status  \\\n",
       "0  0.030670          6 -1.063594          8       1.134721               1   \n",
       "1  0.837096          4 -1.008692          8       1.134721               2   \n",
       "2 -0.042641          1  0.245075          2      -0.420053               3   \n",
       "3  1.057031          1  0.425795          1      -1.197440               2   \n",
       "4 -0.775756          1  1.408154          8       1.134721               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           8             3     2    0      0.148451     -0.216656   \n",
       "1           9             2     2    0     -0.145918     -0.216656   \n",
       "2          14             3     2    0     -0.145918     -0.216656   \n",
       "3          14             2     1    0     -0.145918     -0.216656   \n",
       "4           6             5     1    1     -0.145918     -0.216656   \n",
       "\n",
       "   hours-per-week  native-country  >=50K  \n",
       "0       -0.035429               0      0  \n",
       "1       -2.222119               0      0  \n",
       "2       -0.035429               0      0  \n",
       "3       -0.035429               0      0  \n",
       "4       -0.035429              22      0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_neg_params=[]\n",
    "for i in Continuous_features:\n",
    "    pos=[]\n",
    "    neg=[]\n",
    "    for j in range(X_train.shape[0]):\n",
    "        if Y_train[j]==1:\n",
    "            pos.append(X_train[j][i])\n",
    "        else:\n",
    "            neg.append(X_train[j][i])\n",
    "    temp=[]\n",
    "    temp.append(mean(pos))\n",
    "    temp.append(stdev(pos))\n",
    "    temp.append(mean(neg))\n",
    "    temp.append(stdev(neg))\n",
    "    pos_neg_params.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prior_probablity_each_class(Y_train,target):\n",
    "    count=0\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        if Y_train[i]==target:\n",
    "            count=count+1\n",
    "    return count/Y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conditional_probability_feature(feature_index,X_train,Y_train,target_class,feature):\n",
    "    if feature_index in Continuous_features:\n",
    "        pos=0\n",
    "        for i in range(len(Continuous_features)):\n",
    "            if Continuous_features[i]==feature_index:\n",
    "                pos=i\n",
    "                break\n",
    "        num=0\n",
    "        if target_class==1:\n",
    "            num=standard_normal_distribution(feature,pos_neg_params[pos][0],pos_neg_params[pos][1])\n",
    "        else:\n",
    "            num=standard_normal_distribution(feature,pos_neg_params[pos][2],pos_neg_params[pos][3])\n",
    "        return num\n",
    "    else:\n",
    "        den=0\n",
    "        count=0\n",
    "        for i in range(X_train.shape[0]):\n",
    "            if Y_train[i]==target_class:\n",
    "                den=den+1\n",
    "                if X_train[i][feature_index]==feature:\n",
    "                    count=count+1\n",
    "        return count/den\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(X_train,Y_train,X_test,i):\n",
    "    p_pos=prior_probablity_each_class(Y_train,1)\n",
    "    p_neg=prior_probablity_each_class(Y_train,0)\n",
    "    for j in range(14):\n",
    "        p_pos=p_pos*conditional_probability_feature(j,X_train,Y_train,1,X_test[i][j])\n",
    "    for j in range(14):\n",
    "        p_neg=p_neg*conditional_probability_feature(j,X_train,Y_train,0,X_test[i][j])\n",
    "    if p_pos>=p_neg:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred=[]\n",
    "for i in range(len(X_test)):\n",
    "    Y_pred.append(predict(X_train,Y_train,X_test,i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Naive\n",
      "\n",
      "Accuracy: 0.8093333333333333\n",
      "\n",
      "Precision: 0.6042553191489362\n",
      "\n",
      "Recall: 0.7395833333333334\n",
      "\n",
      "F1_Score: 0.6651053864168619\n",
      "\n",
      "Confusion_Matrix:\n",
      "      0    1\n",
      "0  284  186\n",
      "1  100  930\n"
     ]
    }
   ],
   "source": [
    "metrics=Eval_metrics_naive_bayes(Y_test[:len(X_test)],Y_pred)\n",
    "evaluation_summary('Naive',metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Smoothing techinque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conditional_probability_feature_with_smoothing(feature_index,X_train,Y_train,target_class,feature):\n",
    "    if feature_index in Continuous_features:\n",
    "        pos=0\n",
    "        for i in range(len(Continuous_features)):\n",
    "            if Continuous_features[i]==feature_index:\n",
    "                pos=i\n",
    "                break\n",
    "\n",
    "        num=0\n",
    "        if target_class==1:\n",
    "            num=standard_normal_distribution(feature,pos_neg_params[pos][0],pos_neg_params[pos][1])\n",
    "        else:\n",
    "            num=standard_normal_distribution(feature,pos_neg_params[pos][2],pos_neg_params[pos][3])\n",
    "\n",
    "        return num\n",
    "    else:\n",
    "        den=0\n",
    "        count=0\n",
    "        nc=0\n",
    "        n=0\n",
    "        m=0\n",
    "        for i in range(X_train.shape[0]):\n",
    "            if Y_train[i]==target_class:\n",
    "                den=den+1\n",
    "                n=n+1\n",
    "                if X_train[i][feature_index]==feature:\n",
    "                    nc=nc+1\n",
    "                    count=count+1\n",
    "        if count!=0:\n",
    "            return count/den\n",
    "        # To handle 0 probabilities\n",
    "        m=len(np.unique(df.iloc[:,feature_index]))\n",
    "        return (nc+1)/(n+m)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred=[]\n",
    "for i in range(len(X_test)):\n",
    "    Y_pred.append(predict(X_train,Y_train,X_test,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Naive\n",
      "\n",
      "Accuracy: 0.824\n",
      "\n",
      "Precision: 0.6185897435897436\n",
      "\n",
      "Recall: 0.772\n",
      "\n",
      "F1_Score: 0.6868327402135231\n",
      "\n",
      "Confusion_Matrix:\n",
      "      0    1\n",
      "0  193  119\n",
      "1   57  631\n"
     ]
    }
   ],
   "source": [
    "metrics=Eval_metrics_naive_bayes(Y_test[:len(X_test)],Y_pred)\n",
    "evaluation_summary('Naive',metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Logistic Regression\n",
      "\n",
      "Accuracy: 0.8250372856077554\n",
      "\n",
      "Precision: 0.4525631216526396\n",
      "\n",
      "Recall: 0.7262124002455494\n",
      "\n",
      "F1_Score: 0.5576243224133868\n",
      "\n",
      "Confusion_Matrix:\n",
      "       0     1\n",
      "0  1183  1431\n",
      "1   446  7668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred=classifier.predict(X_test)\n",
    "metrics=Eval_metrics_naive_bayes(Y_pred,Y_test)\n",
    "evaluation_summary('Logistic Regression',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: K-Nearest Neighbours\n",
      "\n",
      "Accuracy: 0.8187919463087249\n",
      "\n",
      "Precision: 0.5734506503442999\n",
      "\n",
      "Recall: 0.6439003436426117\n",
      "\n",
      "F1_Score: 0.6066369890732497\n",
      "\n",
      "Confusion_Matrix:\n",
      "       0     1\n",
      "0  1499  1115\n",
      "1   829  7285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred=classifier.predict(X_test)\n",
    "metrics=Eval_metrics_naive_bayes(Y_pred,Y_test)\n",
    "evaluation_summary('K-Nearest Neighbours',metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvAwe-SsRGKl"
   },
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFJNv4E3RW45"
   },
   "source": [
    "Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CscZOYH-R1GR"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.activations import sigmoid,relu,linear,softmax,tanh\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy,SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbOL-Z9LPt22"
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_test=tf.constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xd_znhGsf9Gy",
    "outputId": "ba8664c4-0310-4b28-9579-6ec2b1e003c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JENCbLcqTmt0",
    "outputId": "5ae3d4e7-81df-42c1-987a-f1bc6ed727c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8O8NPoYXl1M"
   },
   "outputs": [],
   "source": [
    "X_train=tf.constant(X_train)\n",
    "Y_train=tf.constant(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD9rKNhOdG_f"
   },
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "g0AkJiHDT7eL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "EkjnQiNfSQEm",
    "outputId": "c974ffbb-375e-4994-c7a9-70bcfb5af974"
   },
   "outputs": [],
   "source": [
    "model_1=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_1.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_1.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "  num=model_1.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "  Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_1',metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAYKyt-WT7eM"
   },
   "outputs": [],
   "source": [
    "model_2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_2.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_2.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_2.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_2',metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QmHMft4T7eM",
    "outputId": "06005096-b936-488c-a900-cc9aabf658fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Model_3\n",
      "\n",
      "Accuracy: 0.888\n",
      "\n",
      "Confusion_Matrix:\n",
      " [[ 83.   0.   3.   0.   0.   4.   3.   0.   1.   0.]\n",
      " [  0. 125.   0.   1.   0.   0.   0.   1.   0.   1.]\n",
      " [  0.   0. 105.   3.   0.   1.   0.   3.   4.   0.]\n",
      " [  0.   0.   3.  91.   0.   5.   0.   3.   8.   1.]\n",
      " [  0.   0.   0.   0.  88.   0.   0.   1.   1.   3.]\n",
      " [  0.   0.   0.   3.   0.  74.   1.   0.   1.   0.]\n",
      " [  2.   0.   1.   1.   3.   1.  83.   0.   3.   0.]\n",
      " [  0.   0.   1.   2.   0.   0.   0.  85.   1.   1.]\n",
      " [  0.   1.   3.   5.   1.   1.   0.   1.  69.   3.]\n",
      " [  0.   0.   0.   1.  18.   1.   0.   5.   1.  85.]]\n"
     ]
    }
   ],
   "source": [
    "model_3=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=tanh),\n",
    "    Dense(100,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_3.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_3.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_3.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_3',metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gIBEZYpT7eM"
   },
   "outputs": [],
   "source": [
    "model_4=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_4.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_4.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_4.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_4',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lX2QqWs8T7eM",
    "outputId": "3b02e567-baf5-4a8b-eaf8-4525aaa1295f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Model_5\n",
      "\n",
      "Accuracy: 0.799\n",
      "\n",
      "Confusion_Matrix:\n",
      " [[ 82.   0.   1.   0.   0.   0.  10.   0.   0.   0.]\n",
      " [  0. 124.  28.   0.   0.   3.   0.   0.   0.   0.]\n",
      " [  0.   0.  81.  49.   2.   7.   0.   1.   1.   1.]\n",
      " [  2.   0.   2.  56.   0.  37.   0.   4.   3.   7.]\n",
      " [  0.   0.   0.   0. 101.   1.   1.   0.   2.   2.]\n",
      " [  0.   0.   1.   1.   0.  36.   3.   1.   1.   4.]\n",
      " [  1.   0.   0.   0.   2.   0.  72.   0.   0.   0.]\n",
      " [  0.   0.   1.   1.   0.   0.   0.  90.   1.   0.]\n",
      " [  0.   2.   1.   0.   1.   2.   1.   2.  80.   3.]\n",
      " [  0.   0.   1.   0.   4.   1.   0.   1.   1.  77.]]\n"
     ]
    }
   ],
   "source": [
    "model_5=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(10,activation=sigmoid)\n",
    "])\n",
    "\n",
    "model_5.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_5.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_5.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_5',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fyVt7vTT7eN",
    "outputId": "ea4de560-db4e-4180-b673-3cc8a095c550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Model_6\n",
      "\n",
      "Accuracy: 0.917\n",
      "\n",
      "Confusion_Matrix:\n",
      " [[ 83.   0.   0.   1.   1.   1.   4.   1.   3.   0.]\n",
      " [  0. 124.   0.   0.   1.   0.   0.   0.   0.   0.]\n",
      " [  0.   0. 104.   1.   1.   0.   0.   0.   1.   0.]\n",
      " [  1.   0.   1. 101.   0.   2.   0.   3.   1.   0.]\n",
      " [  0.   0.   0.   0.  97.   1.   0.   1.   2.   5.]\n",
      " [  0.   1.   1.   2.   0.  75.   1.   0.   1.   0.]\n",
      " [  1.   0.   0.   0.   1.   3.  82.   0.   1.   0.]\n",
      " [  0.   0.   4.   0.   1.   1.   0.  92.   0.   1.]\n",
      " [  0.   1.   5.   1.   1.   3.   0.   0.  75.   4.]\n",
      " [  0.   0.   1.   1.   7.   1.   0.   2.   5.  84.]]\n"
     ]
    }
   ],
   "source": [
    "model_6=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_6.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_6.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_6.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_6',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGYpoI-2T7eN"
   },
   "outputs": [],
   "source": [
    "model_7=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_7.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_7.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_7.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_7',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSEuoGMvT7eN"
   },
   "outputs": [],
   "source": [
    "model_8=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_8.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_8.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_8.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_8',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dli-AsuHT7eN"
   },
   "outputs": [],
   "source": [
    "model_9=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=sigmoid),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_9.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_9.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_9.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_9',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dl1LjIc7T7eN"
   },
   "outputs": [],
   "source": [
    "model_10=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=sigmoid),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_10.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_10.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_10.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_10',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quPJaqhwT7eN"
   },
   "outputs": [],
   "source": [
    "model_11=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=sigmoid),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_11.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_11.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_11.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_11',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JjRuTjRT7eO",
    "outputId": "47006a32-8a99-4b5f-fbd7-a2f931ae8d27"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [33]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     11\u001B[0m Y_pred\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(X_test\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m---> 13\u001B[0m     num\u001B[38;5;241m=\u001B[39m\u001B[43mmodel_12\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39margmax()\n\u001B[1;32m     14\u001B[0m     Y_pred\u001B[38;5;241m.\u001B[39mappend(num)\n\u001B[1;32m     16\u001B[0m metrics\u001B[38;5;241m=\u001B[39mEval_metrics(Y_test,Y_pred)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2249\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   2247\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_predict_begin()\n\u001B[1;32m   2248\u001B[0m batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2249\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, iterator \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39menumerate_epochs():  \u001B[38;5;66;03m# Single epoch.\u001B[39;00m\n\u001B[1;32m   2250\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[1;32m   2251\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:1307\u001B[0m, in \u001B[0;36mDataHandler.enumerate_epochs\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1305\u001B[0m \u001B[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001B[39;00m\n\u001B[1;32m   1306\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_truncate_execution_to_epoch():\n\u001B[0;32m-> 1307\u001B[0m     data_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1308\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial_epoch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_epochs):\n\u001B[1;32m   1309\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:499\u001B[0m, in \u001B[0;36mDatasetV2.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minside_function():\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[0;32m--> 499\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43miterator_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOwnedIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    501\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset` only supports Python-style \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    502\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miteration in eager mode or within tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:696\u001B[0m, in \u001B[0;36mOwnedIterator.__init__\u001B[0;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[1;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m element_spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    693\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    694\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    695\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot be specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 696\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_next_call_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:721\u001B[0m, in \u001B[0;36mOwnedIterator._create_iterator\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(ds_variant):\n\u001B[1;32m    717\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    718\u001B[0m       gen_dataset_ops\u001B[38;5;241m.\u001B[39manonymous_iterator_v3(\n\u001B[1;32m    719\u001B[0m           output_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_types,\n\u001B[1;32m    720\u001B[0m           output_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_shapes))\n\u001B[0;32m--> 721\u001B[0m   \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_variant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3409\u001B[0m, in \u001B[0;36mmake_iterator\u001B[0;34m(dataset, iterator, name)\u001B[0m\n\u001B[1;32m   3407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m   3408\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3409\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3410\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMakeIterator\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3411\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   3412\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_12=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(100,activation=sigmoid),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_12.compile(optimizer='sgd',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_12.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_12.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_12',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwcHU6ZST7eO"
   },
   "outputs": [],
   "source": [
    "model_13=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_13.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_13.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_13.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_13',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ij3EePo8T7eO"
   },
   "outputs": [],
   "source": [
    "model_14=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(150,activation=relu),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_14.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_14.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_14.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_14',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eq29kPcsT7eO"
   },
   "outputs": [],
   "source": [
    "model_14=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_14.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_14.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_14.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_14',metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0j0ZWCPT7eO"
   },
   "outputs": [],
   "source": [
    "model_15=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(150,activation=tanh),\n",
    "    Dense(10,activation=softmax)\n",
    "])\n",
    "\n",
    "model_15.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "model_15.fit(X_train,Y_train,epochs=3,verbose=0)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    num=model_15.predict(tf.expand_dims(X_test[i],0),verbose=0).argmax()\n",
    "    Y_pred.append(num)\n",
    "\n",
    "metrics=Eval_metrics(Y_test,Y_pred,10)\n",
    "evaluation_summary('Model_15',metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
